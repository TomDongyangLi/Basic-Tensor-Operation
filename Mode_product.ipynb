{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to compute the mode $n$ product $$\\mathcal{Z} = \\mathcal{A}\\times_nU_n$$,where $\\mathcal{A}$ has size $I_1 \\times I_2\\times \\cdots \\times I_d$ and $U_n$ has size $J \\times I_n$. The ouput tensor should have size $I_1 \\times \\cdots\\times I_{n-1}\\times J\\times I_{n+1}\\times \\cdots \\times I_d$, and the calculation follows \n",
    "\n",
    "\n",
    "$$\\mathcal{Z}(i_1,\\cdots,i_{j-1},j,i_{n+1},\\cdots,i_d) = \\sum_{l=1}^{I_n}A(i_1,\\cdots,i_{j-1},l,i_{n+1},\\cdots,i_d)U(j,l)$$\n",
    "\n",
    "The computation can also be done by using unfolding \n",
    "\n",
    "$$\\mathcal{Z}_{(n)} = U\\mathcal{A}_{(n)}$$\n",
    "\n",
    ", where $\\mathcal{Z}_{(n)},\\mathcal{A}_{(n)}$ are the mode $n$ unfolding of $\\mathcal{Z},\\mathcal{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Toy example \n",
    "Let's focus on a small example with size $2\\times 2\\times 2$ and $3\\times 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A: tensor([[[0.0977, 0.4686],\n",
      "         [0.4027, 0.5704]],\n",
      "\n",
      "        [[0.0820, 0.9125],\n",
      "         [0.8529, 0.0545]]])\n",
      "Matrix U: tensor([[0.7287, 0.3158],\n",
      "        [0.4553, 0.2043],\n",
      "        [0.9357, 0.4596]])\n"
     ]
    }
   ],
   "source": [
    "d = 3\n",
    "n = 3\n",
    "r = 2\n",
    "\n",
    "A = torch.rand([r for _ in range(d)])\n",
    "U = torch.rand([n, r])\n",
    "\n",
    "print('Tensor A:', A)\n",
    "print('Matrix U:', U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the mode product between $\\mathcal{A}$ and $U$ for each mode of $\\mathcal{A}$. \n",
    "\n",
    "##### For ***mode 1***, \n",
    "\n",
    "using basic definition $$\\mathcal{Z}(j,i_2,i_3) = \\sum_{l=1}^{I_1}A(l,i_2,i_3)U(j,l)$$, we expect a tensor with size $3\\times 2\\times 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0971, 0.6296],\n",
      "         [0.5628, 0.4329]],\n",
      "\n",
      "        [[0.0612, 0.3998],\n",
      "         [0.3576, 0.2709]],\n",
      "\n",
      "        [[0.1291, 0.8579],\n",
      "         [0.7688, 0.5588]]])\n"
     ]
    }
   ],
   "source": [
    "B = torch.zeros([n,r,r])\n",
    "for i in range(n):\n",
    "    for j in range(r):\n",
    "        for k in range(r):\n",
    "            for l in range(r):\n",
    "                B[i,j,k] = B[i,j,k] + U[i,l]*A[l,j,k]\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using unfolding method, $$\\mathcal{Z}_{(1)} = U\\mathcal{A}_{(1)}$$\n",
    "`torch.moveaxis(A,0,0)` does not change anything\n",
    "\n",
    "`A_1.reshape([n,r,r])` change back from matrix to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0971, 0.6296],\n",
      "         [0.5628, 0.4329]],\n",
      "\n",
      "        [[0.0612, 0.3998],\n",
      "         [0.3576, 0.2709]],\n",
      "\n",
      "        [[0.1291, 0.8579],\n",
      "         [0.7688, 0.5588]]])\n"
     ]
    }
   ],
   "source": [
    "A_1 = torch.moveaxis(A, 0, 0).reshape(A.shape[0],-1)\n",
    "A_1 = U@A_1\n",
    "B = torch.moveaxis(A_1.reshape([n,r,r]), 0, 0)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `tensordot`, we want to change the first mode from size $I_1$ to $J$, \n",
    "\n",
    "so we need to match the first dimension of $\\mathcal{A}$ and the second dimension of $U$. \n",
    "\n",
    "But `tensordot` outputs a tensor with size $I_2\\times I_3\\times J$, and we need $J\\times I_2\\times I_3$\n",
    "\n",
    "so we can \n",
    "- use `B.permute(2,0,1)` to move the last dimension to the first: $(0,1,2)\\to (2,0,1)$. Have to write down all dim index to keep the order of $I_2$ and $I_3$\n",
    "- this can also be done by `torch.moveaxis(B,2,0)` or `B.movedim(2,0)` where they insert the last dim/axis to the first position, while keeping the order of $I_2$ and $I_3$\n",
    "- note that `torch.moveaxis(B,2,0)`:$(0,1,2)\\to (2,0,1)$  is not the same as `torch.moveaxis(B,0,2)`: $(0,1,2)\\to (1,2,0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0971, 0.6296],\n",
      "         [0.5628, 0.4329]],\n",
      "\n",
      "        [[0.0612, 0.3998],\n",
      "         [0.3576, 0.2709]],\n",
      "\n",
      "        [[0.1291, 0.8579],\n",
      "         [0.7688, 0.5588]]])\n"
     ]
    }
   ],
   "source": [
    "B = torch.tensordot(A, U, dims=([0], [1]))\n",
    "B = B.permute(2,0,1)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's do for the same for ***mode 2***\n",
    "\n",
    "using basic definition $$\\mathcal{Z}(i_1,j,i_3) = \\sum_{l=1}^{I_2}A(i_1,l,i_3)U(j,l)$$, we expect a tensor with size $2\\times 3\\times 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1983, 0.5216],\n",
      "         [0.1268, 0.3300],\n",
      "         [0.2765, 0.7007]],\n",
      "\n",
      "        [[0.3290, 0.6822],\n",
      "         [0.2116, 0.4266],\n",
      "         [0.4686, 0.8789]]])\n"
     ]
    }
   ],
   "source": [
    "B = torch.zeros([r,n,r])\n",
    "for i in range(r):\n",
    "    for j in range(n):\n",
    "        for k in range(r):\n",
    "            for l in range(r):\n",
    "                B[i,j,k] = B[i,j,k] + U[j,l]*A[i,l,k]\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using unfolding method, $$\\mathcal{Z}_{(2)} = U\\mathcal{A}_{(2)}$$\n",
    "`torch.moveaxis(A,1,0)` insert the second dimension to the first position and shifts the positions of the other dimensions accordingly.\n",
    "\n",
    "We need this step since only in this way will give us mode 2 fiber as columns of $\\mathcal{A}_{(2)}$\n",
    "\n",
    "`A_2.reshape([n,r,r])` change back from matrix to tensor\n",
    "\n",
    "we need to reshape tensor as size $3\\times 2\\times 2$ since we've changed dimension earlier\n",
    "\n",
    "`moveaxis` allows us to change the dimension back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1983, 0.5216],\n",
      "         [0.1268, 0.3300],\n",
      "         [0.2765, 0.7007]],\n",
      "\n",
      "        [[0.3290, 0.6822],\n",
      "         [0.2116, 0.4266],\n",
      "         [0.4686, 0.8789]]])\n"
     ]
    }
   ],
   "source": [
    "A_2 = torch.moveaxis(A, 1, 0).reshape(A.shape[1],-1)\n",
    "A_2 = U@A_2\n",
    "B = torch.moveaxis(A_2.reshape([n,r,r]), 0, 1)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `tensordot`, we want to change the second mode from size $I_2$ to $J$, \n",
    "\n",
    "so we need to match the second dimension of $\\mathcal{A}$ and the second dimension of $U$. \n",
    "\n",
    "But `tensordot` outputs a tensor with size $I_1\\times I_3\\times J$, and we need $I_1\\times J\\times I_3$\n",
    "\n",
    "so `permute` is required to move the last dimension to the second "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1983, 0.5216],\n",
      "         [0.1268, 0.3300],\n",
      "         [0.2765, 0.7007]],\n",
      "\n",
      "        [[0.3290, 0.6822],\n",
      "         [0.2116, 0.4266],\n",
      "         [0.4686, 0.8789]]])\n"
     ]
    }
   ],
   "source": [
    "B = torch.tensordot(A, U, dims=([1], [1]))\n",
    "B = B.permute(0,2,1)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Last Mode***\n",
    "\n",
    "using basic definition $$\\mathcal{Z}(i_1,i_2,j) = \\sum_{l=1}^{I_3}A(i_1,i_2,l)U(j,l)$$, we expect a tensor with size $2\\times 2\\times 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2192, 0.1402, 0.3068],\n",
      "         [0.4736, 0.2999, 0.6390]],\n",
      "\n",
      "        [[0.3479, 0.2238, 0.4960],\n",
      "         [0.6387, 0.3995, 0.8231]]])\n"
     ]
    }
   ],
   "source": [
    "B = torch.zeros([r,r,n])\n",
    "for i in range(r):\n",
    "    for j in range(r):\n",
    "        for k in range(n):\n",
    "            for l in range(r):\n",
    "                B[i,j,k] = B[i,j,k] + U[k,l]*A[i,j,l]\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using unfolding method, $$\\mathcal{Z}_{(3)} = U\\mathcal{A}_{(3)}$$\n",
    "`torch.moveaxis(A,2,0)` insert the third dimension to the first position and shifts the positions of the other dimensions accordingly.\n",
    "\n",
    "We need this step since only in this way will give us mode 3 fiber as columns of $\\mathcal{A}_{(2)}$\n",
    "\n",
    "`A_3.reshape([n,r,r])` change back from matrix to tensor\n",
    "\n",
    "we need to reshape tensor as size $3\\times 2\\times 2$ since we've changed dimension earlier\n",
    "\n",
    "`moveaxis` allows us to change the dimension back\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2192, 0.1402, 0.3068],\n",
      "         [0.4736, 0.2999, 0.6390]],\n",
      "\n",
      "        [[0.3479, 0.2238, 0.4960],\n",
      "         [0.6387, 0.3995, 0.8231]]])\n"
     ]
    }
   ],
   "source": [
    "A_3 = torch.moveaxis(A, 2, 0).reshape(A.shape[2],-1)\n",
    "A_3 = U@A_3\n",
    "B = torch.moveaxis(A_3.reshape([n,r,r]), 0, 2)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `tensordot`, we want to change the third mode from size $I_3$ to $J$, \n",
    "\n",
    "so we need to match the third dimension of $\\mathcal{A}$ and the second dimension of $U$. \n",
    "\n",
    "`tensordot` outputs a tensor with size $I_1\\times I_2\\times J$, which is we need\n",
    "\n",
    "so `permute` is not required in this case. \n",
    "\n",
    "Note: permute(0,1,2) did not change anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2192, 0.1402, 0.3068],\n",
      "         [0.4736, 0.2999, 0.6390]],\n",
      "\n",
      "        [[0.3479, 0.2238, 0.4960],\n",
      "         [0.6387, 0.3995, 0.8231]]])\n"
     ]
    }
   ],
   "source": [
    "B = torch.tensordot(A, U, dims=([2], [1]))\n",
    "B = B.permute(0,1,2) # didn;t change anything\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. More factors\n",
    "\n",
    "We want to compute $$\\mathcal{Z} = \\mathcal{A}\\times_1U_1\\times_2 U_2\\times_3U_3$$,where $\\mathcal{A}$ has size $I_1 \\times I_2\\times \\cdots \\times I_d$ and $U_n$ has size $J_n \\times I_n$. The ouput tensor should have size $J_1 \\times J_2\\times  \\cdots \\times J_d$, and the calculation follows \n",
    "\n",
    "\n",
    "$$\\mathcal{Z}(j_1,j_2,\\cdots,j_d) = \\sum_{i_1=1}^{I_1}\\cdots\\sum_{i_d=1}^{I_d}A(i_1,i_2,\\cdots,i_d)U_1(j_1,i_1)\\cdots U_d(j_d,i_d)$$\n",
    "\n",
    "\n",
    "Consider an easy case with size $2\\times 2\\times 2$ for tensor and $3\\times 2$ for all matrix factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 3\n",
    "n = 1000\n",
    "r = 10\n",
    "U = []\n",
    "A = torch.rand([r for _ in range(d)])\n",
    "U.append(torch.rand([n, r]))\n",
    "U.append(torch.rand([n, r]))\n",
    "U.append(torch.rand([n, r]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Definition\n",
    "\n",
    "$$\\mathcal{Z}(j_1,j_2,j_3) = \\sum_{i_1=1}^{I_1}\\sum_{i_2=1}^{I_2}\\sum_{i_3=1}^{I_3}A(i_1,i_2,i_3)U_1(j_1,i_1)U_2(j_2,i_2)U_3(j_3,i_3)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time= time.time()\n",
    "#B_def = torch.zeros([n,n,n])\n",
    "#for j1 in range(n):\n",
    "#    for j2 in range(n):\n",
    "#        for j3 in range(n):\n",
    "#            for i1 in range(r):\n",
    "#                for i2 in range(r):\n",
    "#                    for i3 in range(r):\n",
    "#                        B_def[j1,j2,j3] = B_def[j1,j2,j3] + U[0][j1,i1]*U[1][j2,i2]*U[2][j3,i3]*A[i1,i2,i3]\n",
    "                \n",
    "#print('Time taken:', time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using unfolding strategy\n",
    "\n",
    "iteratively unfolding, folding for each mode $$\\mathcal{Z}_{(n)} = U_n\\mathcal{A}_{(n)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.3908851146697998\n"
     ]
    }
   ],
   "source": [
    "start_time= time.time()\n",
    "B_unf = A.clone()\n",
    "shape = list(B_unf.shape)\n",
    "for i in range(d):\n",
    "    B_i = torch.moveaxis(B_unf, i, 0).reshape(B_unf.shape[i],-1)\n",
    "    B_i = U[i]@B_i\n",
    "    shape[i] = n\n",
    "    B_unf = torch.moveaxis(B_i.reshape(shape), 0, i)\n",
    "print('Time taken:', time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the other way of unfolding approach\n",
    "$$\\mathcal{Z}_{(1)} = U_1\\mathcal{A}_{(1)}(U_3\\otimes U_2)^T$$\n",
    "$$\\mathcal{Z}_{(2)} = U_2\\mathcal{A}_{(2)}(U_3\\otimes U_1)^T$$\n",
    "$$\\mathcal{Z}_{(3)} = U_3\\mathcal{A}_{(3)}(U_2\\otimes U_1)^T$$\n",
    "\n",
    "\n",
    "***Note***: Reshape function in python is using lexicographical order, which means that the third index iterates the fastest, so actually we need\n",
    "\n",
    "$$\\mathcal{Z}_{(1)} = U_1\\mathcal{A}_{(1)}(U_2\\otimes U_3)^T$$\n",
    "$$\\mathcal{Z}_{(2)} = U_2\\mathcal{A}_{(2)}(U_1\\otimes U_3)^T$$\n",
    "$$\\mathcal{Z}_{(3)} = U_3\\mathcal{A}_{(3)}(U_1\\otimes U_2)^T$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.6207261085510254\n"
     ]
    }
   ],
   "source": [
    "start_time= time.time()\n",
    "U_kron = torch.ones(1)\n",
    "B_kron = A.clone()\n",
    "for i in range(1,d):\n",
    "    U_kron = torch.kron(U_kron,U[i])\n",
    "        \n",
    "B_1 = B_kron.reshape(B_kron.shape[0],-1)\n",
    "B_kron = U[0]@B_1@U_kron.T\n",
    "B_kron = B_kron.reshape([n for _ in range(d)])\n",
    "\n",
    "print('Time taken:', time.time()-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.8304221630096436\n"
     ]
    }
   ],
   "source": [
    "start_time= time.time()\n",
    "U_kron_2 = torch.ones(1)\n",
    "B_kron_2 = A.clone()\n",
    "for i in range(d):\n",
    "    if i!=1:\n",
    "        U_kron_2 = torch.kron(U_kron_2,U[i])\n",
    "        \n",
    "B_2 = B_kron_2.movedim(1,0).reshape(B_kron_2.shape[1],-1)\n",
    "B_kron_2 = U[1]@B_2@U_kron_2.T\n",
    "B_kron_2 = B_kron_2.reshape([n for _ in range(d)]).movedim(0,1)\n",
    "\n",
    "print('Time taken:', time.time()-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.070183277130127\n"
     ]
    }
   ],
   "source": [
    "start_time= time.time()\n",
    "U_kron_3 = torch.ones(1)\n",
    "B_kron_3 = A.clone()\n",
    "for i in range(d):\n",
    "    if i!=2:\n",
    "        U_kron_3 = torch.kron(U_kron_3,U[i])\n",
    "        \n",
    "B_3 = B_kron_3.movedim(2,0).reshape(B_kron_3.shape[2],-1)\n",
    "B_kron_3 = U[2]@B_3@U_kron_3.T\n",
    "B_kron_3 = B_kron_3.reshape([n for _ in range(d)]).movedim(0,2)\n",
    "\n",
    "print('Time taken:', time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(B_kron, B_kron_2))\n",
    "print(torch.allclose(B_kron, B_kron_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `tensordot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.4466838836669922\n"
     ]
    }
   ],
   "source": [
    "start_time= time.time()\n",
    "B_dot = A.clone()\n",
    "for i, Ui in enumerate(U):\n",
    "    B_dot = torch.tensordot(B_dot, Ui, dims=([i], [1]))\n",
    "    B_dot = B_dot.movedim(-1, i)\n",
    "print('Time taken:', time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(B_unf, B_kron))\n",
    "print(torch.allclose(B_unf, B_dot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like `tensordot` and the first unfolding approach works the best\n",
    "\n",
    "Probably choose `tensordot` for less code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
